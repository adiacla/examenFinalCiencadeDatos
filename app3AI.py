# app.py - versi√≥n actualizada: evaluaci√≥n por pregunta para el cuestionario
# Nota: elimina claves API en el c√≥digo y usa variables de entorno (.env o exportadas).
#       Ejemplo local: crear .env con GENAI_API_KEY=tu_api_key y pip install python-dotenv
import re
import streamlit as st
import sqlite3
import pdfplumber
import requests
import pandas as pd
from io import BytesIO
import os
import json
from datetime import datetime, timezone

# Intentar cargar .env si est√° disponible (opcional, no obligatorio)
try:
    from dotenv import load_dotenv

    load_dotenv()
except Exception:
    pass

# Inicializar cliente Gemeni/GenAI de forma segura (usar GENAI_API_KEY en el entorno)
client = None
gemini_model = "gemini-2.0-flash"
try:
    from google import genai

    api_key = os.getenv("GEMINI_API_KEY")  # lee de la variable de entorno
    if api_key:
        client = genai.Client(api_key=api_key)
    else:
        try:
            # intenta crear client sin api_key expl√≠cita (ADC u otra configuraci√≥n)
            client = genai.Client()
        except Exception:
            client = None
except Exception:
    client = None

DB_PATH = "notas.db"

def init_db():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS badges (
        url TEXT PRIMARY KEY,
        id TEXT,
        nrc TEXT,
        nombre TEXT,
        curso TEXT,
        horas TEXT,
        fecha TEXT,
        valido INTEGER,
        mensaje TEXT,
        nota_taller REAL
    )
    """)
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS taller_resultados (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        id_estudiante TEXT,
        nrc_curso TEXT,
        nota_taller REAL,
        feedback TEXT,
        comentarios TEXT,
        fecha_registro TEXT
    )
    """)
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS respuestas_cuestionario (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        id_estudiante TEXT,
        nrc_curso TEXT,
        respuestas TEXT,
        nota_cuestionario REAL,
        feedback TEXT,
        fecha_registro TEXT
    )
    """)
    conn.commit()
    conn.close()

# DB helpers
def guardar_en_db(id_est, nrc, nombre, curso, horas, fecha, url, valido, mensaje, nota_taller=None):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute("""
    INSERT OR REPLACE INTO badges (url, id, nrc, nombre, curso, horas, fecha, valido, mensaje, nota_taller)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (url, id_est, nrc, nombre, curso, horas, fecha, int(bool(valido)), mensaje, nota_taller))
    conn.commit()
    conn.close()

def obtener_registros():
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query("SELECT * FROM badges", conn)
    conn.close()
    return df

def obtener_calificaciones_badges():
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query("""
        SELECT 
            id AS id_estudiante,
            nrc AS nrc_curso,
            SUM(CASE WHEN valido=1 THEN 1 ELSE 0 END) * 0.25 AS calificacion_badge
        FROM badges
        GROUP BY id, nrc
    """, conn)
    conn.close()
    return df

def guardar_resultado_taller(id_estudiante, nrc_curso, nota_taller, feedback, comentarios):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    # Guardar fecha como ISO string (timezone-aware) para evitar adaptadores de datetime
    fecha_iso = datetime.now(timezone.utc).isoformat()
    c.execute("""
        INSERT INTO taller_resultados (id_estudiante, nrc_curso, nota_taller, feedback, comentarios, fecha_registro)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (id_estudiante, nrc_curso, nota_taller, feedback, comentarios, fecha_iso))
    conn.commit()
    conn.close()

def obtener_aggregado_taller():
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query("""
        SELECT 
            id_estudiante,
            nrc_curso,
            SUM(COALESCE(nota_taller,0)) AS calificacion_taller,
            COUNT(*) AS n_registros_taller
        FROM taller_resultados
        GROUP BY id_estudiante, nrc_curso
    """, conn)
    conn.close()
    return df

def guardar_respuestas_cuestionario(id_estudiante, nrc_curso, respuestas_dict, nota_cuestionario, feedback):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    fecha_iso = datetime.now(timezone.utc).isoformat()
    c.execute("""
        INSERT INTO respuestas_cuestionario (id_estudiante, nrc_curso, respuestas, nota_cuestionario, feedback, fecha_registro)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (
        id_estudiante,
        nrc_curso,
        json.dumps(respuestas_dict, ensure_ascii=False),
        nota_cuestionario,
        feedback,
        fecha_iso
    ))
    conn.commit()
    conn.close()

def obtener_aggregado_cuestionario():
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query("""
        SELECT 
            id_estudiante,
            nrc_curso,
            SUM(COALESCE(nota_cuestionario,0)) AS calificacion_cuestionario,
            COUNT(*) AS n_registros_cuestionario
        FROM respuestas_cuestionario
        GROUP BY id_estudiante, nrc_curso
    """, conn)
    conn.close()
    return df

def obtener_ultimo_taller():
    conn = sqlite3.connect(DB_PATH)
    query = """
        SELECT tr.id_estudiante, tr.nrc_curso, tr.nota_taller AS calificacion_taller, tr.fecha_registro
        FROM taller_resultados tr
        INNER JOIN (
            SELECT id_estudiante, nrc_curso, MAX(fecha_registro) AS max_fecha
            FROM taller_resultados
            GROUP BY id_estudiante, nrc_curso
        ) ult
        ON tr.id_estudiante = ult.id_estudiante
        AND tr.nrc_curso = ult.nrc_curso
        AND tr.fecha_registro = ult.max_fecha
    """
    df = pd.read_sql_query(query, conn)
    conn.close()
    return df

def obtener_ultimo_cuestionario():
    conn = sqlite3.connect(DB_PATH)
    query = """
        SELECT rc.id_estudiante, rc.nrc_curso, rc.nota_cuestionario AS calificacion_cuestionario, rc.fecha_registro
        FROM respuestas_cuestionario rc
        INNER JOIN (
            SELECT id_estudiante, nrc_curso, MAX(fecha_registro) AS max_fecha
            FROM respuestas_cuestionario
            GROUP BY id_estudiante, nrc_curso
        ) ult
        ON rc.id_estudiante = ult.id_estudiante
        AND rc.nrc_curso = ult.nrc_curso
        AND rc.fecha_registro = ult.max_fecha
    """
    df = pd.read_sql_query(query, conn)
    conn.close()
    return df

# PDF extraction
def extraer_texto_y_urls(file_bytes):
    texto = ""
    urls = []
    with pdfplumber.open(BytesIO(file_bytes)) as pdf:
        pages_text = []
        for page in pdf.pages:
            page_text = page.extract_text() or ""
            pages_text.append(page_text)
            texto += page_text + "\n"

        # Juntamos todo el texto para capturar URLs que puedan romperse en saltos de l√≠nea
        whole_text = "\n".join(pages_text)

        # Eliminar caracteres invisibles comunes (soft-hyphen, etc.)
        whole_text = whole_text.replace("\u00ad", "")  # soft-hyphen
        whole_text = whole_text.replace("\u200b", "")  # zero-width space

        # Buscar coincidencias que empiecen en credly.com/go/ y que puedan tener saltos o espacios
        raw_matches = re.findall(
            r"(https?://(?:www\.)?credly\.com/go/[A-Za-z0-9\-\._~%/\\\n\r\t]+)",
            whole_text,
            flags=re.IGNORECASE,
        )

        for m in raw_matches:
            # Normalizar: quitar saltos de l√≠nea/espacios internos
            url = re.sub(r"\s+", "", m)

            # Quitar puntuaci√≥n terminal que suele venir pegada en textos (.,;:) o par√©ntesis/quotes
            url = url.rstrip(".,;:)\"]'")

            # Extraer solo la porci√≥n v√°lida del badge: https://www.credly.com/go/<token>
            # donde <token> suele ser alfanum√©rico con - _ % ~ . etc. cortamos antes de sufijos como 'Powered'
            m_token = re.match(r'^(https?://(?:www\.)?credly\.com/go/[A-Za-z0-9\-_~%.]+)', url, flags=re.IGNORECASE)
            if m_token:
                clean_url = m_token.group(1)
            else:
                # fallback: si no coincide, dejamos la url sin espacios ni puntuaci√≥n terminal
                clean_url = url

            # Tambi√©n quitar sufijos comunes pegados por la extracci√≥n
            clean_url = re.sub(r'(Powered|powered|Poweredby|poweredby)$', '', clean_url, flags=re.IGNORECASE)

            urls.append(clean_url)

    # Deduplicar preservando el orden
    unique_urls = list(dict.fromkeys(urls))
    return texto.strip(), unique_urls

def procesar_texto(texto):
    lineas = [l.strip() for l in texto.splitlines() if l.strip()]

    curso_idx = None
    for i, linea in enumerate(lineas):
        if re.match(r"^AWS", linea, re.IGNORECASE):
            curso_idx = i
            break

    if curso_idx is None or curso_idx + 2 >= len(lineas):
        return None, None, None, None

    curso = lineas[curso_idx]
    horas = lineas[curso_idx + 1]
    fecha = lineas[curso_idx + 2]
    nombre = " ".join(lineas[:curso_idx])

    return nombre, curso, horas, fecha

def validar_badge_publico(url):
    try:
        resp = requests.get(url, timeout=10)
        if resp.status_code == 200:
            return True, "‚úÖ Badge v√°lido"
        else:
            return False, f"‚ùå Badge no v√°lido (status {resp.status_code})"
    except Exception as e:
        return False, f"‚ùå Error al validar: {e}"

# GenAI response extraction helper
def _extract_text_from_genai_response(response):
    try:
        if hasattr(response, "text") and isinstance(response.text, str):
            return response.text
        if hasattr(response, "candidates"):
            try:
                c = response.candidates
                if len(c) > 0:
                    cand = c[0]
                    if hasattr(cand, "content"):
                        cont = cand.content
                        if isinstance(cont, list) and len(cont) > 0:
                            first = cont[0]
                            if isinstance(first, dict) and "text" in first:
                                return first["text"]
                            return str(first)
                    return str(cand)
            except Exception:
                pass
        return str(response)
    except Exception:
        return str(response)

# Evaluaci√≥n taller (igual que antes)
def evaluar_taller_redes_neuronales(contenido_estudiante: str):
    """
    Llama a Gemini para evaluar el taller. Devuelve (nota_taller_float_or_None, raw_text_response, parsed_json_or_None).
    - Si la respuesta incluye un JSON con la estructura esperada, lo parsea y extrae la nota.
    - Si no, intenta extraer un n√∫mero del texto como fallback num√©rico.
    """
    if client is None:
        return None, "API de evaluaci√≥n (Gemini) no configurada. Define la variable de entorno GENAI_API_KEY o configura las credenciales.", None

    prompt = f"""
Eres un profesor experto en ML y te envia el estudiante un archivo con un deployment de gradio.
La nota m√°xima es: 1.50 puntos.
Objetivo: evaluar el archivo llamado  app.py que implementa una interfaz para triage de un modelo de Ml preentrenado y con interaccion con Gemini (ver requisitos m√≠nimos).
Devuelve SOLO un JSON con la siguiente estructura:

{{
  "nota_taller": 1.50,
  "detalle": [
    {{"criterio":"implementacion","score":0.00,"comentario":""}},
    {{"criterio":"ejecucion","score":0.00,"comentario":""}},
    {{"criterio":"preprocesamiento","score":0.00,"comentario":""}},
    {{"criterio":"evidencia","score":0.00,"comentario":""}}
  ],
  "resumen": "Texto corto con evidencias y fallos detectados"
}}

Revisa que el app.py tenga: 1) Entrada del paciente, 2) Resultado ESI + probabilidad, 3) Resumen del paciente (datos crudos) 4) Recomendaci√≥n cl√≠nica generada por Gemini (acciones inmediatas, pruebas y monitorizaci√≥n).
A continuaci√≥n el c√≥digo del estudiante:
{contenido_estudiante}
"""

    try:
        response = client.models.generate_content(model=gemini_model, contents=prompt)
        raw = _extract_text_from_genai_response(response)

        # Intentar extraer JSON completo de la respuesta
        parsed = None
        match_json = re.search(r"\{(?:.|\s)*\}", raw, flags=re.DOTALL)
        if match_json:
            try:
                parsed = json.loads(match_json.group(0))
            except Exception:
                parsed = None

        # Determinar nota (preferir parsed JSON, si no fallback num√©rico)
        nota_taller = None
        if isinstance(parsed, dict):
            if "nota_taller" in parsed:
                try:
                    nota_taller = float(parsed.get("nota_taller", 0.0))
                except Exception:
                    nota_taller = None
            elif "nota" in parsed:
                try:
                    nota_taller = float(parsed.get("nota", 0.0))
                except Exception:
                    nota_taller = None

        # Fallback: buscar primer n√∫mero en el raw
        if nota_taller is None:
            m = re.search(r"(\d+(\.\d+)?)", raw)
            if m:
                try:
                    nota_taller = float(m.group(1))
                except Exception:
                    nota_taller = None

        if nota_taller is None:
            nota_taller = 0.0

        nota_taller = max(0.0, min(1.5, round(nota_taller, 2)))

        return nota_taller, raw, parsed

    except Exception as e:
        return None, f"Error en la llamada a la API: {e}", None

# ----------------------------
# NUEVA: Evaluaci√≥n por pregunta (cada respuesta en su propio prompt)
# ----------------------------
def evaluar_respuestas_abiertas(respuestas_estudiante):
    """Eval√∫a cada respuesta individualmente enviando un prompt por pregunta y luego agrega la nota."""
    if client is None:
        return None, "API de evaluaci√≥n (Gemini) no configurada. Define la variable de entorno GENAI_API_KEY o configura las credenciales.", None

    # Respuestas esperadas para 20 preguntas
    respuestas_esperadas = {
        1: "La multicolinealidad ocurre cuando dos o m√°s variables est√°n altamente correlacionadas; se detecta mediante VIF o matriz de correlaci√≥n y se mitiga eliminando variables, usando PCA o regularizaci√≥n.",
        2: "L1 induce sparsidad eliminando coeficientes; L2 reduce magnitudes sin anularlos. L1 es √∫til para selecci√≥n de caracter√≠sticas; L2 para estabilizar modelos.",
        3: "La regresi√≥n log√≠stica usa log-loss porque modela probabilidades de clasificaci√≥n; MSE no es adecuada por su superficie no convexa y mal comportamiento en clasificaci√≥n.",
        4: "Gini mide impureza como probabilidad de clasificaci√≥n incorrecta; entrop√≠a mide desorden. Gini es m√°s r√°pido; entrop√≠a puede ser m√°s informativa.",
        5: "RandomForest reduce varianza al combinar m√∫ltiples √°rboles mediante bagging y muestreo aleatorio de variables, disminuyendo sobreajuste.",
        6: "n_estimators, max_depth, max_features, min_samples_split, bootstrap afectan complejidad, diversidad de √°rboles y riesgo de overfitting.",
        7: "XGBoost aplica boosting basado en gradientes usando segunda derivada (Hessian), regularizaci√≥n expl√≠cita y t√©cnicas como shrinkage y column subsampling.",
        8: "learning_rate, max_depth, n_estimators, subsample, colsample_bytree, gamma, lambda ayudan a controlar complejidad y evitar sobreajuste.",
        9: "Un Pipeline puede incluir un StandardScaler, PCA o SelectKBest, y un modelo como LogisticRegression; asegura preprocesamiento consistente en validaci√≥n y prueba.",
        10: "Feature selection elige variables relevantes (ej: SelectKBest). Feature extraction crea variables nuevas (ej: PCA).",
        11: "GridSearchCV eval√∫a combinaciones de hiperpar√°metros con validaci√≥n cruzada interna para seleccionar el mejor modelo seg√∫n una m√©trica.",
        12: "Cuando el espacio de b√∫squeda es grande o costoso; RandomizedSearchCV cubre el espacio m√°s eficientemente al muestrear combinaciones aleatorias.",
        13: "La varianza explicada indica cu√°nta informaci√≥n conserva cada componente; se seleccionan componentes que acumulen 90‚Äì95% o mediante el m√©todo del codo.",
        14: "PCA puede eliminar dimensiones que ayudan al clustering o distorsionar relaciones no lineales, afectando la calidad de los clusters.",
        15: "PCA es no supervisado y maximiza varianza; LDA es supervisado y maximiza la separaci√≥n entre clases.",
        16: "K-Means no decide k; el usuario lo define. Optimiza la suma de distancias intra-cluster para ese valor dado.",
        17: "Elbow busca un punto donde la reducci√≥n de SSE disminuye notablemente; silueta eval√∫a cohesi√≥n y separaci√≥n, maximiz√°ndola para el mejor k.",
        18: "Asume clusters esf√©ricos y de tama√±o similar; falla con formas complejas, densidades distintas o presencia de ruido.",
        19: "PCA puede mejorar K-Means eliminando ruido; pero tambi√©n puede borrar informaci√≥n √∫til. Se comparan m√©tricas como silueta y separaci√≥n visual.",
        20: "Debe revisarse cohesi√≥n, separaci√≥n, distribuci√≥n por cluster, interpretabilidad, tama√±os balanceados y consistencia con el dominio."
}

    n_preg = len(respuestas_esperadas)
    per_q = round(3.0 / n_preg, 2)  # cada pregunta vale ~0.20

    results = []
    total = 0.0
    detalles_lines = []

    for k in range(1, n_preg + 1):
        expected = respuestas_esperadas[k]
        student = respuestas_estudiante.get(k, "").replace("\n", " ").strip()

        # Prompt espec√≠fico por pregunta: pide SOLO un JSON con question, score, feedback
        prompt = f"""Eres un profesor experto en Ciencia de Datos y AWS.
Compara la respuesta esperada (texto) con la respuesta del estudiante y eval√∫a la calidad, adem√°s da una retroalimentaci√≥n de Plagio. Si la detectecci√≥n de plagio muestra superior al 70% la nota final debe ser la mitad de la nota obtenida.
La nota m√°xima es de 3.0 puntos, es decir debes calcular el valor con respecto a las preguntas con validez, consistentes y completitud de cada pregunta.

INSTRUCCIONES:
- Devuelve SOLO un JSON v√°lido con EXACTAMENTE estos campos: {{
    "question": {k},
    "score": X,          # n√∫mero decimal entre 0 y {per_q} con 2 decimales
    "feedback": "Texto corto de retroalimentaci√≥n del examen con el analisis de plagio."
  }}
- No devuelvas texto adicional fuera del JSON.
- S√© conciso y objetivo.
- Ten en cuenta la respuesta esperada: {expected}

Respuesta del estudiante:
{student}
"""

        try:
            response = client.models.generate_content(model=gemini_model, contents=prompt)
            raw = _extract_text_from_genai_response(response).strip()
            # Extraer JSON si lo devuelve
            match_json = re.search(r"\{(?:.|\s)*\}", raw, flags=re.DOTALL)
            score = 0.0
            feedback = ""
            if match_json:
                try:
                    obj = json.loads(match_json.group(0))
                    score = float(obj.get("score", 0.0))
                    feedback = obj.get("feedback", "")
                except Exception:
                    # fallback: buscar n√∫mero y tomar el resto como feedback
                    mnum = re.search(r"(\d+(\.\d+)?)", raw)
                    if mnum:
                        score = float(mnum.group(1))
                        feedback = raw
                    else:
                        score = 0.0
                        feedback = raw
            else:
                # si no hay JSON, intentar extraer un n√∫mero y el texto como feedback
                mnum = re.search(r"(\d+(\.\d+)?)", raw)
                if mnum:
                    score = float(mnum.group(1))
                    feedback = raw
                else:
                    score = 0.0
                    feedback = raw

            # Asegurar l√≠mites por pregunta
            if score < 0.0:
                score = 0.0
            if score > per_q:
                score = per_q

            # Normalizar a 2 decimales
            score = round(score, 2)
            total += score
            results.append({"question": k, "score": score, "feedback": feedback})
            detalles_lines.append(f"Pregunta {k}: {score:.2f}/{per_q}\n{feedback}")

        except Exception as e:
            # En caso de error con la API, anotar 0 y el mensaje de error
            results.append({"question": k, "score": 0.0, "feedback": f"Error evaluaci√≥n: {e}"})
            detalles_lines.append(f"Pregunta {k}: 0.00/{per_q}\nError evaluaci√≥n: {e}")

    # Asegurar m√°ximo 3.0 y redondeo final
    total = round(min(total, 3.0), 2)

    # Construir feedback legible
    detalles_lines.append(f"\nNota final: {total:.2f} / 3.00")
    feedback_text = "\n\n".join(detalles_lines)

    return total, feedback_text, results

# ----------------------------
# STREAMLIT UI
# ----------------------------
st.set_page_config(page_title="Validador de Badges + Taller", layout="wide")
init_db()
st.title("Calificador de Badges de Credly en Inteligencia Artificial")

tabs = st.tabs([
    "üìÇ Cargar Badges",
    "üìä Validar Badges a DB",
    "üìù Evaluar Taller",
    "üìù Evaluar Cuestionario",
    "üìà Calificaciones"
])


# --- Reemplaza/inserta estas secciones en tu app.py ---

# ---------- Inicializaci√≥n (antes de crear widgets) ----------
# Si ya tienes id_estudiante/nrc_curso en session_state, y quieres que
# aparezcan como valores por defecto en los text_input, copia esos valores
# a las keys del widget ANTES de crear los widgets.
if "id_estudiante" in st.session_state and "input_id" not in st.session_state:
    st.session_state["input_id"] = st.session_state["id_estudiante"]
if "nrc_curso" in st.session_state and "input_nrc" not in st.session_state:
    st.session_state["input_nrc"] = st.session_state["nrc_curso"]

# ----------------------------
# Pesta√±a 0 - Subida de archivo (usar sin reasignar input_id/input_nrc)
# ----------------------------
with tabs[0]:
    st.markdown("## Examen de Inteligencia Artificial 2025 UNAB")
    st.markdown("Sube el PDF del badge obtenido en [Credly](https://www.credly.com/) tras completar el ID y el NRC.")
    # Creamos los widgets (estos ya mantienen su valor en st.session_state["input_id"] / ["input_nrc"])
    id_input = st.text_input("ID del estudiante", key="input_id")
    nrc_input = st.text_input("NRC del curso", key="input_nrc")
    uploaded_file = st.file_uploader("Subir archivo PDF", type=["pdf"])

    if uploaded_file is not None and id_input and nrc_input:
        if st.button("Procesar y Guardar", key="procesar_guardar_pdf"):
            file_bytes = uploaded_file.read()
            texto, urls = extraer_texto_y_urls(file_bytes)
            urls_credly = [u for u in urls if u.startswith("https://www.credly.com/go/")]

            if not urls_credly:
                st.warning("‚ö†Ô∏è El PDF no tiene una URL de Credly para validar.")
            else:
                nombre, curso, horas, fecha = procesar_texto(texto)
                if not all([nombre, curso, horas, fecha]):
                    st.error("El PDF no tiene el formato esperado (nombre, curso, horas, fecha).")
                else:
                    for url in urls_credly:
                        valido, mensaje = validar_badge_publico(url)
                        # Guardar en la DB usando los valores ingresados (id_input, nrc_input)
                        guardar_en_db(id_input, nrc_input, nombre, curso, horas, fecha, url, valido, mensaje, None)

                        # NO reasignes las claves ligadas a widgets (input_id/input_nrc)
                        # st.session_state["input_id"] = id_input   # <-- eliminar (provoca excepci√≥n)
                        # st.session_state["input_nrc"] = nrc_input  # <-- eliminar

                        # Si quieres claves internas que uses en otras pesta√±as, s√≠ crea otras claves:
                        st.session_state["id_estudiante"] = id_input
                        st.session_state["nrc_curso"] = nrc_input

                        st.success(f"Guardado en BD: {id_input}, {nrc_input}, {nombre}, {curso}, {horas}, {fecha}, {url}")
                        st.info(mensaje)

# Pesta√±a 2 - Ver registros
with tabs[1]:
    st.header("Validar que los Badge fueron Registrados")
    df = obtener_registros()
    if df.empty:
        st.info("No hay registros guardados todav√≠a.")
    else:
        if st.session_state.get("input_id"):
            df = df[df["id"] == st.session_state["input_id"].strip()]
        if st.session_state.get("input_nrc"):
            df = df[df["nrc"] == st.session_state["input_nrc"].strip()]
        st.dataframe(df, width='stretch')

# ----------------------------
# Pesta√±a 3 - Evaluar Taller (actualizada para mostrar Resumen + Detalle)
# ----------------------------
with tabs[2]:
    st.header("Evaluar Taller de Redes Neuronales")
    st.markdown(
    """
    üì• [Abrir un taller de deployment (Examen_ID_NRC.ipynb)](https://colab.research.google.com/drive/1GIIxfjRlyDKYoOX6CEmlS3JCZif2iWnJ?usp=sharing)
    """,  unsafe_allow_html=True)

    archivos_taller = st.file_uploader(
        "Subir soluci√≥n en Python (.py o .ipynb) - sube un solo archivo con la soluci√≥n del taller o varios archivos si el taller tiene m√∫ltiples partes.", 
        type=["py", "ipynb"],
        accept_multiple_files=True,
        key="uploader_taller"
    )

    comentarios_taller = st.text_area(
        "Comentarios / Observaciones (opcional)", 
        height=120, 
        key="comentarios_taller"
    )

    if "taller_results" not in st.session_state:
        st.session_state["taller_results"] = []  # lista de dicts: {filename, nota, feedback_raw, feedback_json, timestamp}

    current_id = st.session_state.get("input_id", "").strip()
    current_nrc = st.session_state.get("input_nrc", "").strip()

    if not current_id or not current_nrc:
        st.warning("Debes ingresar ID y NRC en la pesta√±a 'Cargar PDF' antes de evaluar talleres.")
    else:
        if archivos_taller:
            for idx, archivo in enumerate(archivos_taller):
                st.markdown(f"**Archivo {idx+1}:** {archivo.name}")
                col1, col2 = st.columns([1, 3])

                with col1:
                    if st.button(f"Evaluar {archivo.name}", key=f"eval_file_{idx}"):
                        try:
                            raw_bytes = archivo.read()
                            nombre = archivo.name.lower()
                            if nombre.endswith(".py"):
                                contenido_estudiante = raw_bytes.decode("utf-8", errors="ignore")
                            elif nombre.endswith(".ipynb"):
                                try:
                                    nb_json = json.loads(raw_bytes.decode("utf-8"))
                                except Exception:
                                    nb_json = json.loads(raw_bytes.decode("latin-1"))
                                celdas = []
                                for celda in nb_json.get("cells", []):
                                    if celda.get("cell_type") == "code":
                                        celdas.append("".join(celda.get("source", [])))
                                contenido_estudiante = "\n".join(celdas)
                            else:
                                st.error("‚ö†Ô∏è Formato de archivo no soportado.")
                                contenido_estudiante = None

                            if not contenido_estudiante:
                                st.error("No se pudo extraer el contenido del archivo.")
                                continue

                            # Evaluar (Gemini)
                            nota_taller, feedback_raw, feedback_json = evaluar_taller_redes_neuronales(contenido_estudiante)

                            if nota_taller is None:
                                st.warning("‚ö†Ô∏è No se pudo calcular la nota autom√°ticamente. Revisa el feedback.")
                                # guardar registro con nota None -> 0.0
                                nota_to_save = 0.0
                            else:
                                nota_to_save = float(nota_taller)

                            # Guardar en BD y en session_state
                            guardar_resultado_taller(
                                current_id,
                                current_nrc,
                                nota_to_save,
                                feedback_raw,
                                comentarios_taller or ""
                            )

                            registro = {
                                "filename": archivo.name,
                                "nota": nota_to_save,
                                "feedback_raw": feedback_raw,
                                "feedback_json": feedback_json,
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            }
                            st.session_state["taller_results"].append(registro)

                            st.success(f"‚úÖ Nota del taller guardada para {archivo.name}: {nota_to_save} / 1.5")
                            st.session_state["nota_taller"] = nota_to_save

                            # Mostrar feedback inmediato: abrimos dos subtabs Resumen / Detalle
                            st.markdown("### Resultado de la evaluaci√≥n")
                            sub1, sub2 = st.tabs(["Resumen", "Detalle"])
                            with sub1:
                                # Resumen: si hay JSON mostrar campo resumen, sino mostrar primera l√≠nea raw
                                if isinstance(feedback_json, dict) and feedback_json.get("resumen"):
                                    st.write(feedback_json.get("resumen"))
                                else:
                                    # mostrar un fragmento del raw como resumen
                                    preview = feedback_raw.strip().splitlines()
                                    st.write(preview[0] if preview else "Sin resumen.")
                                st.write(f"Nota final: {nota_to_save} / 1.5")

                            with sub2:
                                # Detalle: si feedback_json tiene 'detalle' iterable, mostrarlo formateado
                                if isinstance(feedback_json, dict) and isinstance(feedback_json.get("detalle"), list):
                                    st.markdown("**Desglose por criterios**")
                                    for item in feedback_json.get("detalle", []):
                                        criterio = item.get("criterio", "criterio")
                                        score = item.get("score", 0.0)
                                        comentario = item.get("comentario", item.get("feedback", ""))
                                        st.write(f"- {criterio}: {score:.2f} ‚Äî {comentario}")
                                else:
                                    # Si no hay detalle estructurado, mostramos raw con resaltado
                                    st.markdown("**Feedback (raw)**")
                                    st.code(feedback_raw, language="")
                                    # Intentar buscar l√≠neas que parezcan puntuaciones
                                    st.markdown("**Fragmentos relevantes**")
                                    # Mostrar fragmentos donde aparezcan palabras clave
                                    keywords = ["implementacion", "ejecucion", "preprocesamiento", "evidencia", "nota"]
                                    for kw in keywords:
                                        for line in (feedback_raw or "").splitlines():
                                            if kw.lower() in line.lower():
                                                st.write(f"- {line.strip()}")

                        except Exception as e:
                            st.error(f"‚ùå Error al procesar el archivo: {e}")

                with col2:
                    st.write("")  # espacio o mostrar preview si quieres

        else:
            st.info("No hay archivos subidos para evaluar. Sube uno o varios y pulsa 'Evaluar' en el archivo deseado.")

        # Mostrar resumen de todas las evaluaciones de esta sesi√≥n (tabla y selector)
        st.markdown("---")
        st.subheader("Historial de evaluaciones en esta sesi√≥n")
        if not st.session_state["taller_results"]:
            st.info("A√∫n no se ha evaluado ning√∫n archivo en esta sesi√≥n.")
        else:
            df_resumen = pd.DataFrame(st.session_state["taller_results"])
            display_df = df_resumen[["filename", "nota", "timestamp"]].sort_values(by="timestamp", ascending=False).reset_index(drop=True)
            st.dataframe(display_df, width='stretch')

            seleccion = st.selectbox("Selecciona un archivo para ver detalle:", display_df["filename"].tolist(), key="taller_res_selector")
            registro = next((r for r in st.session_state["taller_results"] if r["filename"] == seleccion), None)
            if registro:
                st.markdown("### Detalle seleccionado")
                st.write(f"- Archivo: {registro['filename']}")
                st.write(f"- Nota: {registro['nota']} / 1.5")
                st.write(f"- Fecha: {registro['timestamp']}")

                # Mostrar resumen y detalle como tabs
                rsub1, rsub2 = st.tabs(["Resumen", "Detalle"])
                with rsub1:
                    if isinstance(registro.get("feedback_json"), dict) and registro["feedback_json"].get("resumen"):
                        st.write(registro["feedback_json"]["resumen"])
                    else:
                        # fallback: mostrar primera l√≠nea del raw
                        first_line = (registro.get("feedback_raw") or "").strip().splitlines()
                        st.write(first_line[0] if first_line else "Sin resumen.")

                with rsub2:
                    if isinstance(registro.get("feedback_json"), dict) and isinstance(registro["feedback_json"].get("detalle"), list):
                        for item in registro["feedback_json"]["detalle"]:
                            criterio = item.get("criterio", "criterio")
                            score = item.get("score", 0.0)
                            comentario = item.get("comentario", item.get("feedback", ""))
                            st.write(f"- {criterio}: {score:.2f} ‚Äî {comentario}")
                    else:
                        st.code(registro.get("feedback_raw", ""), language="")

                # Descargar feedback raw
                st.download_button(
                    label="üì• Descargar feedback (raw) como texto",
                    data=registro.get("feedback_raw", ""),
                    file_name=f"feedback_{registro['filename']}.txt",
                    mime="text/plain"
                )

# Pesta√±a 4 - Evaluar Cuestionario (ahora usa evaluaci√≥n por pregunta)
with tabs[3]:
    st.header("Cuestionario de Preguntas Abiertas (Responde en 1-3 l√≠neas cada una)")
    preguntas_abiertas = [
        "En una regresi√≥n lineal m√∫ltiple, ¬øc√≥mo interpretar√≠as la multicolinealidad y qu√© t√©cnicas podr√≠as usar para detectarla y mitigarla?",
        "Explica c√≥mo funciona la regularizaci√≥n L1 y L2 en modelos supervisados y en qu√© casos elegir√≠as cada una.",
        "¬øCu√°l es la funci√≥n de costo utilizada en regresi√≥n log√≠stica y por qu√© no se utiliza MSE?",
        "Explica la diferencia entre Gini impurity y entropy en modelos basados en √°rboles y c√≥mo afectan el rendimiento.",
        "¬øQu√© ventajas aporta RandomForest frente a un solo √°rbol de decisi√≥n en t√©rminos de sesgo y varianza?",
        "Menciona los hiperpar√°metros m√°s importantes de RandomForest en Scikit-Learn y explica su impacto.",
        "Explica c√≥mo funciona XGBoost y c√≥mo difiere del Gradient Boosting tradicional.",
        "¬øQu√© hiperpar√°metros clave ajustar√≠as en XGBoost para evitar sobreajuste?",
        "Describe c√≥mo implementar un Pipeline de Scikit-Learn que incluya escalado, selecci√≥n de caracter√≠sticas y un modelo final.",
        "¬øQu√© diferencia existe entre feature selection y feature extraction? Menciona un ejemplo de cada uno.",
        "¬øC√≥mo se utiliza GridSearchCV y qu√© tipo de validaci√≥n interna realiza?",
        "¬øCu√°ndo es recomendable utilizar RandomizedSearchCV en lugar de GridSearchCV?",
        "Explica el concepto de varianza explicada en PCA y c√≥mo seleccionar el n√∫mero √≥ptimo de componentes.",
        "¬øQu√© problemas pueden surgir al aplicar PCA antes de realizar clustering con K-Means?",
        "¬øCu√°l es la diferencia entre PCA y LDA como m√©todos de reducci√≥n de dimensionalidad?",
        "¬øC√≥mo decide K-Means el valor de k al ejecutar el algoritmo?",
        "Explica el m√©todo del codo (Elbow Method) y el √≠ndice de silueta para evaluar el n√∫mero √≥ptimo de clusters.",
        "¬øQu√© suposiciones realiza K-Means sobre la forma de los clusters y por qu√© pueden ser limitantes?",
        "¬øC√≥mo interpretar√≠as los resultados de un an√°lisis de clustering al comparar PCA + KMeans vs KMeans sobre datos originales?",
        "¬øQu√© aspectos revisar√≠as en un cluster report para evaluar si los grupos formados son √∫tiles?"
    ]

    respuestas_usuario = {}
    for i, pregunta in enumerate(preguntas_abiertas, start=1):
        st.markdown(f"**Pregunta {i}:** {pregunta}")
        respuesta = st.text_area(f"Respuesta {i}", key=f"resp_{i}", height=120)
        respuestas_usuario[i] = respuesta or ""

    if st.button("Evaluar Cuestionario", key="boton_evaluar_cuestionario"):
        if st.session_state.get("input_id") and st.session_state.get("input_nrc"):
            with st.spinner("Evaluando respuestas pregunta por pregunta..."):
                nota_cuestionario, feedback_text, parsed = evaluar_respuestas_abiertas(respuestas_usuario)

            if nota_cuestionario is not None:
                st.success(f"‚úÖ Nota cuestionario: {nota_cuestionario:.2f} / 3.0")
                guardar_respuestas_cuestionario(
                    st.session_state["input_id"].strip(),
                    st.session_state["input_nrc"].strip(),
                    respuestas_usuario,
                    nota_cuestionario,
                    feedback_text
                )
                st.session_state["nota_cuestionario"] = nota_cuestionario
            else:
                st.warning(f"‚ö†Ô∏è No se pudo obtener una nota num√©rica del modelo. {feedback_text}")

            st.subheader("Retroalimentaci√≥n del cuestionario")
            st.markdown(feedback_text)
        else:
            st.error("‚ö†Ô∏è Debes haber ingresado ID y NRC en la pesta√±a 'Cargar PDF' antes de evaluar.")

# Pesta√±a 5 - Calificaciones finales
with tabs[4]:
    st.header("üìà Resumen de Calificaciones")
    df_badges = obtener_calificaciones_badges()
    df_taller = obtener_ultimo_taller()
    df_cuestionario = obtener_ultimo_cuestionario()

    df_merge = (
        df_badges
        .merge(df_taller, on=["id_estudiante", "nrc_curso"], how="outer")
        .merge(df_cuestionario, on=["id_estudiante", "nrc_curso"], how="outer")
    )

    for col in ["calificacion_badge", "calificacion_taller", "calificacion_cuestionario"]:
        if col not in df_merge.columns:
            df_merge[col] = 0.0
        else:
            # Forzamos a num√©rico (convierte valores no num√©ricos a NaN), luego rellenamos
            df_merge[col] = pd.to_numeric(df_merge[col], errors="coerce").fillna(0.0)

    df_merge["nota_total"] = (
        df_merge["calificacion_badge"] +
        df_merge["calificacion_taller"] +
        df_merge["calificacion_cuestionario"]
    )

    id_filter = st.session_state.get("input_id", "").strip()
    nrc_filter = st.session_state.get("input_nrc", "").strip()

    if id_filter:
        df_merge = df_merge[df_merge["id_estudiante"] == id_filter]

    if nrc_filter:
        df_merge = df_merge[df_merge["nrc_curso"] == nrc_filter]

    if df_merge.empty:
        st.info("No hay calificaciones registradas a√∫n para este estudiante y curso.")
    else:
        st.subheader("Resumen de calificaciones")
        st.dataframe(
            df_merge.reset_index(drop=True)[[
                "id_estudiante",
                "nrc_curso",
                "calificacion_badge",
                "calificacion_taller",
                "calificacion_cuestionario",
                "nota_total"
            ]],
            width='stretch'
        )
        st.info("‚öñÔ∏è Nota m√°xima posible = 5.0 (Badges 0.5 + Taller 1.5 + Cuestionario 3.0)")

    try:
        with open(DB_PATH, "rb") as f:
            st.download_button(
                label="üì• Descargar base de datos SQLite",
                data=f,
                file_name="badges.db",
                mime="application/octet-stream"
            )
    except Exception as e:
        st.error(f"No se pudo preparar la descarga de la DB: {e}")


st.write("")  # espacio final


